# analyze_data.py
# ƒê·ªçc v√† ph√¢n t√≠ch d·ªØ li·ªáu t·ª´ ks-nj4/data, b√°o c√°o s·ªë l∆∞·ª£ng t·ª´ng lo·∫°i v√† nh√£n
# python ks-nj4/analyze_data.py

import os
import json
from pathlib import Path
from collections import defaultdict
from typing import Dict, List, Set
from datetime import datetime
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')  # S·ª≠ d·ª•ng backend kh√¥ng c·∫ßn GUI

# ============================================================================
# C·∫§U H√åNH - THAY ƒê·ªîI C√ÅC THAM S·ªê ·ªû ƒê√ÇY
# ============================================================================

# ƒê∆∞·ªùng d·∫´n th∆∞ m·ª•c d·ªØ li·ªáu
DATA_DIR = Path("ks-nj4/data/datasets")  # Th∆∞ m·ª•c d·ªØ li·ªáu c·∫ßn ph√¢n t√≠ch

# C√°c split c·∫ßn x·ª≠ l√Ω
SPLITS = ['test', 'train', 'val']

# Mapping category ID sang t√™n (s·∫Ω ƒë∆∞·ª£c t·ª± ƒë·ªông x√°c ƒë·ªãnh d·ª±a tr√™n s·ªë l·∫ßn xu·∫•t hi·ªán)
CATEGORY_NAMES = {
    1: "brown_planthopper",           # R·∫ßy n√¢u (BPH) - Class nhi·ªÅu nh·∫•t
    2: "whitebacked_planthopper",     # R·∫ßy l∆∞ng tr·∫Øng (WBPH) - Class th·ª© 2
    3: "rice_leaf_miner",            # S√¢u ƒÉn l√° l√∫a (RLM) - Class √≠t nh·∫•t
}

# ============================================================================

def count_category_occurrences(all_stats: Dict[str, Dict]) -> Dict[int, int]:
    """
    ƒê·∫øm s·ªë l·∫ßn xu·∫•t hi·ªán c·ªßa m·ªói category_id trong to√†n b·ªô dataset
    
    Returns:
        Dict {category_id: s·ªë_l·∫ßn_xu·∫•t_hi·ªán}
    """
    category_counts = defaultdict(int)
    
    for split, stats in all_stats.items():
        if stats is None:
            continue
        
        for cat_id, count in stats['category_annotations'].items():
            category_counts[cat_id] += count
    
    return dict(category_counts)

def determine_category_mapping(category_counts: Dict[int, int]) -> Dict[int, str]:
    """
    T·ª± ƒë·ªông x√°c ƒë·ªãnh mapping category_id sang t√™n d·ª±a tr√™n s·ªë l·∫ßn xu·∫•t hi·ªán
    
    Logic:
    - Category xu·∫•t hi·ªán nhi·ªÅu nh·∫•t ‚Üí brown_planthopper (R·∫ßy n√¢u - BPH)
    - Category xu·∫•t hi·ªán th·ª© 2 ‚Üí whitebacked_planthopper (R·∫ßy l∆∞ng tr·∫Øng - WBPH)
    - Category xu·∫•t hi·ªán √≠t nh·∫•t ‚Üí rice_leaf_miner (S√¢u ƒÉn l√° l√∫a - RLM)
    
    Returns:
        Dict {category_id: t√™n_category}
    """
    if len(category_counts) == 0:
        return {}
    
    # S·∫Øp x·∫øp theo s·ªë l·∫ßn xu·∫•t hi·ªán (gi·∫£m d·∫ßn)
    sorted_categories = sorted(category_counts.items(), key=lambda x: x[1], reverse=True)
    
    # Mapping theo th·ª© t·ª±
    mapping = {}
    expected_names = [
        "brown_planthopper",        # Nhi·ªÅu nh·∫•t
        "whitebacked_planthopper",  # Th·ª© 2
        "rice_leaf_miner"           # √çt nh·∫•t
    ]
    
    for idx, (cat_id, count) in enumerate(sorted_categories):
        if idx < len(expected_names):
            mapping[cat_id] = expected_names[idx]
        else:
            # N·∫øu c√≥ nhi·ªÅu h∆°n 3 categories, gi·ªØ nguy√™n t√™n t·ª´ CATEGORY_NAMES
            mapping[cat_id] = CATEGORY_NAMES.get(cat_id, f"category_{cat_id}")
    
    return mapping

# ============================================================================

def read_yolo_label_file(txt_file: Path) -> List[List[float]]:
    """ƒê·ªçc file YOLO label (.txt) v√† tr·∫£ v·ªÅ danh s√°ch annotations"""
    labels = []
    try:
        if txt_file.exists():
            with open(txt_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line:
                        coords = [float(x) for x in line.split()]
                        if len(coords) >= 5:
                            labels.append(coords[:5])  # class_id, x_center, y_center, width, height
    except Exception as e:
        print(f"  ‚ö†Ô∏è  L·ªói khi ƒë·ªçc {txt_file}: {e}")
    return labels

def count_files_in_directory(directory: Path, extensions: List[str]) -> int:
    """ƒê·∫øm s·ªë file trong th∆∞ m·ª•c v·ªõi c√°c extension cho tr∆∞·ªõc"""
    if not directory.exists():
        return 0
    
    count = 0
    for ext in extensions:
        count += len(list(directory.glob(f"*.{ext}"))) + len(list(directory.glob(f"*.{ext.upper()}")))
    
    return count

def analyze_split(split: str, data_dir: Path) -> Dict:
    """
    Ph√¢n t√≠ch m·ªôt split t·ª´ YOLO format
    
    Returns:
        Dict v·ªõi th·ªëng k√™ chi ti·∫øt
    """
    print(f"\n{'=' * 70}")
    print(f"Ph√¢n t√≠ch split: {split.upper()}")
    print(f"{'=' * 70}")
    
    # ƒê·∫øm images th·ª±c t·∫ø trong th∆∞ m·ª•c
    images_dir = data_dir / "images" / split
    labels_dir = data_dir / "labels" / split
    
    if not images_dir.exists():
        print(f"‚ö†Ô∏è  Th∆∞ m·ª•c {images_dir} kh√¥ng t·ªìn t·∫°i, b·ªè qua...")
        return None
    
    if not labels_dir.exists():
        print(f"‚ö†Ô∏è  Th∆∞ m·ª•c {labels_dir} kh√¥ng t·ªìn t·∫°i, b·ªè qua...")
        return None
    
    # ƒê·∫øm images th·ª±c t·∫ø
    image_count_actual = count_files_in_directory(images_dir, ['jpg', 'jpeg', 'png', 'JPG', 'JPEG', 'PNG'])
    
    # T√¨m t·∫•t c·∫£ file ·∫£nh (bao g·ªìm c·∫£ .jpeg, .JPEG)
    image_files = (list(images_dir.glob("*.jpg")) + list(images_dir.glob("*.JPG")) +
                   list(images_dir.glob("*.jpeg")) + list(images_dir.glob("*.JPEG")) +
                   list(images_dir.glob("*.png")) + list(images_dir.glob("*.PNG")))
    
    # Lo·∫°i b·ªè tr√πng l·∫∑p (n·∫øu c√≥)
    image_files = list(set(image_files))
    
    # ƒê·∫øm s·ªë l·∫ßn xu·∫•t hi·ªán c·ªßa m·ªói class_id
    class_annotations = defaultdict(int)  # class_id (YOLO) -> s·ªë annotations
    class_images = defaultdict(set)  # class_id -> set(image_names)
    images_with_labels = set()
    images_without_labels = set()
    images_processed = set()  # ƒê·ªÉ ƒë·∫£m b·∫£o m·ªói ·∫£nh ch·ªâ ƒë∆∞·ª£c ƒë·∫øm m·ªôt l·∫ßn
    image_to_classes = defaultdict(set)  # image_name -> set(class_ids)
    total_annotations = 0
    
    # ƒê·ªçc t·ª´ng file label
    for image_file in image_files:
        image_name = image_file.stem
        # Tr√°nh ƒë·∫øm tr√πng n·∫øu c√≥ file c√πng t√™n v·ªõi extension kh√°c
        if image_name in images_processed:
            continue
        images_processed.add(image_name)
        
        label_file = labels_dir / f"{image_name}.txt"
        
        if label_file.exists():
            labels = read_yolo_label_file(label_file)
            if labels:
                images_with_labels.add(image_name)
                for label in labels:
                    class_id = int(label[0])  # YOLO class_id
                    class_annotations[class_id] += 1
                    class_images[class_id].add(image_name)
                    image_to_classes[image_name].add(class_id)
                    total_annotations += 1
            else:
                images_without_labels.add(image_name)
        else:
            images_without_labels.add(image_name)
    
    # ƒê·∫£m b·∫£o t·ªïng s·ªë images = c√≥ nh√£n + kh√¥ng c√≥ nh√£n
    total_images_counted = len(images_with_labels) + len(images_without_labels)
    
    # Th·ªëng k√™
    stats = {
        'split': split,
        'total_images_json': total_images_counted,  # T·ªïng s·ªë images ƒë√£ x·ª≠ l√Ω (c√≥ nh√£n + kh√¥ng c√≥ nh√£n)
        'total_images_actual': image_count_actual,
        'images_with_labels': len(images_with_labels),
        'images_without_labels': len(images_without_labels),
        'total_annotations': total_annotations,
        'category_annotations': dict(class_annotations),  # L∆∞u d∆∞·ªõi t√™n category_annotations ƒë·ªÉ t∆∞∆°ng th√≠ch
        'category_images': {cat_id: len(img_set) for cat_id, img_set in class_images.items()},
        'images_with_multiple_categories': sum(1 for classes in image_to_classes.values() if len(classes) > 1),
    }
    
    # Ki·ªÉm tra t√≠nh nh·∫•t qu√°n
    if total_images_counted != len(images_with_labels) + len(images_without_labels):
        print(f"  ‚ö†Ô∏è  Warning: T·ªïng s·ªë images kh√¥ng kh·ªõp! ƒê√£ x·ª≠ l√Ω: {total_images_counted}, C√≥ nh√£n: {len(images_with_labels)}, Kh√¥ng c√≥ nh√£n: {len(images_without_labels)}")
    
    print(f"  - T·ªïng images ƒë√£ x·ª≠ l√Ω: {stats['total_images_json']}")
    print(f"  - T·ªïng images th·ª±c t·∫ø trong th∆∞ m·ª•c: {stats['total_images_actual']}")
    print(f"  - Images c√≥ nh√£n: {stats['images_with_labels']}")
    print(f"  - Images kh√¥ng c√≥ nh√£n: {stats['images_without_labels']}")
    print(f"  - T·ªïng annotations: {stats['total_annotations']}")
    print(f"  - S·ªë class_ids t√¨m th·∫•y: {len(class_annotations)}")
    for class_id in sorted(class_annotations.keys()):
        print(f"    Class {class_id}: {class_annotations[class_id]:,} annotations, {len(class_images[class_id]):,} images")
    
    return stats

def generate_report(all_stats: Dict[str, Dict], data_dir: Path):
    """T·∫°o b√°o c√°o chi ti·∫øt v√† l∆∞u v√†o file TXT"""
    from datetime import datetime
    
    report_file = data_dir / "analysis_report.txt"
    
    # T·ªïng h·ª£p d·ªØ li·ªáu
    total_images_json = 0
    total_images_actual = 0
    total_images_with_labels = 0
    total_images_without_labels = 0
    total_annotations = 0
    total_category_annotations = defaultdict(int)
    total_category_images = defaultdict(int)
    total_images_multiple_categories = 0
    
    # Th·ªëng k√™ theo split
    split_stats = {}
    
    for split, stats in all_stats.items():
        if stats is None:
            continue
        
        total_images_json += stats['total_images_json']
        total_images_actual += stats['total_images_actual']
        total_images_with_labels += stats['images_with_labels']
        total_images_without_labels += stats['images_without_labels']
        total_annotations += stats['total_annotations']
        total_images_multiple_categories += stats.get('images_with_multiple_categories', 0)
        
        for cat_id, count in stats['category_annotations'].items():
            total_category_annotations[cat_id] += count
        
        for cat_id, count in stats['category_images'].items():
            total_category_images[cat_id] += count  # C·ªông s·ªë images t·ª´ m·ªói split (c√≥ th·ªÉ tr√πng n·∫øu image c√≥ nhi·ªÅu categories)
    
        split_stats[split] = stats
    
    # ƒê·∫øm s·ªë l·∫ßn xu·∫•t hi·ªán v√† x√°c ƒë·ªãnh mapping t·ª± ƒë·ªông
    category_counts = count_category_occurrences(all_stats)
    category_mapping = determine_category_mapping(category_counts)
    
    # T·∫°o n·ªôi dung b√°o c√°o
    report_lines = []
    report_lines.append("=" * 80)
    report_lines.append("B√ÅO C√ÅO PH√ÇN T√çCH D·ªÆ LI·ªÜU T·ª™ KS-NJ4/DATA")
    report_lines.append("=" * 80)
    report_lines.append(f"Ng√†y t·∫°o: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report_lines.append(f"Th∆∞ m·ª•c d·ªØ li·ªáu: {DATA_DIR}")
    report_lines.append("")
    
    # Hi·ªÉn th·ªã mapping t·ª± ƒë·ªông
    report_lines.append("=" * 80)
    report_lines.append("MAPPING T·ª∞ ƒê·ªòNG D·ª∞A TR√äN S·ªê L·∫¶N XU·∫§T HI·ªÜN")
    report_lines.append("=" * 80)
    report_lines.append("S·ªë l·∫ßn xu·∫•t hi·ªán c·ªßa m·ªói class_id (YOLO) trong to√†n b·ªô dataset:")
    if len(category_counts) == 0:
        report_lines.append("  Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu!")
    else:
        sorted_counts = sorted(category_counts.items(), key=lambda x: x[1], reverse=True)
        for cat_id, count in sorted_counts:
            category_name = category_mapping.get(cat_id, f"category_{cat_id}")
            rank = sorted_counts.index((cat_id, count)) + 1
            if rank == 1:
                rank_text = "NHI·ªÄU NH·∫§T ‚Üí R·∫ßy n√¢u (BPH)"
            elif rank == 2:
                rank_text = "TH·ª® 2 ‚Üí R·∫ßy l∆∞ng tr·∫Øng (WBPH)"
            elif rank == 3:
                rank_text = "√çT NH·∫§T ‚Üí S√¢u ƒÉn l√° l√∫a (RLM)"
            else:
                rank_text = f"X·∫æP H·∫†NG {rank}"
            report_lines.append(f"  Class {cat_id} (YOLO): {count:,} l·∫ßn xu·∫•t hi·ªán - {rank_text} - {category_name}")
    report_lines.append("")
    
    report_lines.append("=" * 80)
    report_lines.append("1. T·ªîNG QUAN")
    report_lines.append("=" * 80)
    report_lines.append(f"üìä T·ªîNG S·ªê H√åNH ·∫¢NH: {total_images_json:,}")
    report_lines.append(f"  - S·ªë h√¨nh ·∫£nh C√ì nh√£n (c√≥ annotations): {total_images_with_labels:,}")
    report_lines.append(f"  - S·ªë h√¨nh ·∫£nh KH√îNG c√≥ nh√£n: {total_images_without_labels:,}")
    report_lines.append(f"  - S·ªë h√¨nh ·∫£nh c√≥ nhi·ªÅu lo·∫°i r·∫ßy: {total_images_multiple_categories:,}")
    report_lines.append("")
    report_lines.append(f"üìä T·ªîNG S·ªê ANNOTATIONS: {total_annotations:,}")
    report_lines.append("")
    report_lines.append(f"üìÅ T·ªïng s·ªë file ·∫£nh th·ª±c t·∫ø trong th∆∞ m·ª•c: {total_images_actual:,}")
    report_lines.append("")
    
    # T·ªâ l·ªá
    if total_images_json > 0:
        pct_with_labels = (total_images_with_labels / total_images_json) * 100
        pct_without_labels = (total_images_without_labels / total_images_json) * 100
        report_lines.append("T·ªâ l·ªá h√¨nh ·∫£nh:")
        report_lines.append(f"  - C√ì nh√£n: {pct_with_labels:.2f}%")
        report_lines.append(f"  - KH√îNG c√≥ nh√£n: {pct_without_labels:.2f}%")
        report_lines.append("")
    
    report_lines.append("=" * 80)
    report_lines.append("2. TH·ªêNG K√ä THEO T·ª™NG SPLIT")
    report_lines.append("=" * 80)
    for split in SPLITS:
        if split not in split_stats or split_stats[split] is None:
            continue
        
        stats = split_stats[split]
        report_lines.append(f"\n{split.upper()}:")
        report_lines.append(f"  - T·ªïng s·ªë h√¨nh ·∫£nh: {stats['total_images_json']:,}")
        report_lines.append(f"  - T·ªïng s·ªë h√¨nh ·∫£nh th·ª±c t·∫ø: {stats['total_images_actual']:,}")
        report_lines.append(f"  - S·ªë h√¨nh ·∫£nh C√ì nh√£n: {stats['images_with_labels']:,}")
        report_lines.append(f"  - S·ªë h√¨nh ·∫£nh KH√îNG c√≥ nh√£n: {stats['images_without_labels']:,}")
        report_lines.append(f"  - T·ªïng s·ªë annotations: {stats['total_annotations']:,}")
        
        if stats['total_images_json'] > 0:
            pct_with = (stats['images_with_labels'] / stats['total_images_json']) * 100
            pct_without = (stats['images_without_labels'] / stats['total_images_json']) * 100
            report_lines.append(f"  - T·ªâ l·ªá C√ì nh√£n: {pct_with:.2f}%")
            report_lines.append(f"  - T·ªâ l·ªá KH√îNG c√≥ nh√£n: {pct_without:.2f}%")
    report_lines.append("")
    
    report_lines.append("=" * 80)
    report_lines.append("3. TH·ªêNG K√ä THEO T·ª™NG LO·∫†I R·∫¶Y (CLASS)")
    report_lines.append("=" * 80)
    # S·ª≠ d·ª•ng category_mapping, n·∫øu kh√¥ng c√≥ th√¨ d√πng category_id c√≥ trong d·ªØ li·ªáu
    all_category_ids = set(total_category_annotations.keys())
    for category_id in sorted(all_category_ids):
        cat_name = category_mapping.get(category_id, CATEGORY_NAMES.get(category_id, f"category_{category_id}"))
        ann_count = total_category_annotations.get(category_id, 0)
        img_count = total_category_images.get(category_id, 0)
        
        report_lines.append(f"\nClass {category_id} (YOLO) - {cat_name}:")
        report_lines.append(f"  - T·ªïng s·ªë annotations: {ann_count:,}")
        report_lines.append(f"  - T·ªïng s·ªë h√¨nh ·∫£nh c√≥ lo·∫°i n√†y: {img_count:,}")
        
        if total_annotations > 0:
            pct_ann = (ann_count / total_annotations) * 100
            report_lines.append(f"  - T·ªâ l·ªá annotations: {pct_ann:.2f}%")
        
        # Chi ti·∫øt theo split
        report_lines.append(f"  - Chi ti·∫øt theo split:")
        for split in SPLITS:
            if split not in split_stats or split_stats[split] is None:
                continue
            split_ann_count = split_stats[split]['category_annotations'].get(category_id, 0)
            split_img_count = split_stats[split]['category_images'].get(category_id, 0)
            if split_ann_count > 0 or split_img_count > 0:
                report_lines.append(f"    + {split.upper()}: {split_ann_count:,} annotations, {split_img_count:,} images")
    report_lines.append("")
    
    report_lines.append("=" * 80)
    report_lines.append("4. PH√ÇN B·ªê ANNOTATIONS THEO CLASS")
    report_lines.append("=" * 80)
    if total_annotations > 0:
        for category_id in sorted(all_category_ids):
            cat_name = category_mapping.get(category_id, CATEGORY_NAMES.get(category_id, f"category_{category_id}"))
            ann_count = total_category_annotations.get(category_id, 0)
            pct = (ann_count / total_annotations) * 100
            report_lines.append(f"Class {category_id} (YOLO) - {cat_name}: {ann_count:,} annotations ({pct:.2f}%)")
    report_lines.append("")
    
    # T√≠nh l·∫°i t·ªâ l·ªá cho ph·∫ßn t√≥m t·∫Øt
    pct_with_labels_final = (total_images_with_labels / total_images_json * 100) if total_images_json > 0 else 0
    pct_without_labels_final = (total_images_without_labels / total_images_json * 100) if total_images_json > 0 else 0
    
    report_lines.append("=" * 80)
    report_lines.append("5. T√ìM T·∫ÆT")
    report_lines.append("=" * 80)
    report_lines.append(f"üìä T·ªîNG S·ªê H√åNH ·∫¢NH: {total_images_json:,}")
    report_lines.append(f"  - C√≥ nh√£n: {total_images_with_labels:,} ({pct_with_labels_final:.2f}%)")
    report_lines.append(f"  - Kh√¥ng c√≥ nh√£n: {total_images_without_labels:,} ({pct_without_labels_final:.2f}%)")
    report_lines.append("")
    report_lines.append(f"üìä T·ªîNG S·ªê ANNOTATIONS: {total_annotations:,}")
    report_lines.append("")
    report_lines.append("S·ªë l∆∞·ª£ng annotations theo t·ª´ng lo·∫°i:")
    for category_id in sorted(all_category_ids):
        cat_name = category_mapping.get(category_id, CATEGORY_NAMES.get(category_id, f"category_{category_id}"))
        ann_count = total_category_annotations.get(category_id, 0)
        img_count = total_category_images.get(category_id, 0)
        if total_annotations > 0:
            pct = (ann_count / total_annotations) * 100
            report_lines.append(f"  - {cat_name}: {ann_count:,} annotations ({pct:.2f}%), {img_count:,} images")
    report_lines.append("")
    
    report_lines.append("=" * 80)
    report_lines.append("K·∫æT TH√öC B√ÅO C√ÅO")
    report_lines.append("=" * 80)
    
    # Ghi file
    try:
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(report_lines))
        print(f"\n‚úì ƒê√£ l∆∞u b√°o c√°o ph√¢n t√≠ch: {report_file}")
        return report_file
    except Exception as e:
        print(f"‚ö†Ô∏è  L·ªói khi l∆∞u b√°o c√°o: {e}")
        return None

def create_charts(all_stats: Dict[str, Dict], category_mapping: Dict[int, str], 
                  total_images_with_labels: int, total_images_without_labels: int,
                  total_annotations: int, total_category_annotations: Dict[int, int],
                  data_dir: Path):
    """T·∫°o c√°c bi·ªÉu ƒë·ªì b√°o c√°o"""
    try:
        # Thi·∫øt l·∫≠p font ƒë·ªÉ hi·ªÉn th·ªã ti·∫øng Vi·ªát (n·∫øu c√≥)
        plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial', 'Tahoma']
        plt.rcParams['axes.unicode_minus'] = False
        
        # T·∫°o figure v·ªõi nhi·ªÅu subplots
        fig = plt.figure(figsize=(16, 12))
        
        # 1. Bi·ªÉu ƒë·ªì s·ªë l∆∞·ª£ng annotations theo t·ª´ng class (Bar chart)
        ax1 = plt.subplot(2, 2, 1)
        sorted_categories = sorted(total_category_annotations.items(), key=lambda x: x[1], reverse=True)
        class_ids = [cat_id for cat_id, _ in sorted_categories]
        ann_counts = [count for _, count in sorted_categories]
        class_names = [category_mapping.get(cat_id, f"Class {cat_id}") for cat_id in class_ids]
        
        bars = ax1.bar(range(len(class_ids)), ann_counts, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])
        ax1.set_xlabel('Class (YOLO)', fontsize=12, fontweight='bold')
        ax1.set_ylabel('S·ªë l∆∞·ª£ng Annotations', fontsize=12, fontweight='bold')
        ax1.set_title('S·ªë l∆∞·ª£ng Annotations theo t·ª´ng Class', fontsize=14, fontweight='bold')
        ax1.set_xticks(range(len(class_ids)))
        ax1.set_xticklabels([f"Class {cid}\n({name})" for cid, name in zip(class_ids, class_names)], 
                           rotation=0, ha='center', fontsize=10)
        ax1.grid(axis='y', alpha=0.3)
        
        # Th√™m gi√° tr·ªã l√™n m·ªói c·ªôt
        for i, (bar, count) in enumerate(zip(bars, ann_counts)):
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height,
                    f'{count:,}',
                    ha='center', va='bottom', fontsize=10, fontweight='bold')
        
        # 2. Pie chart ph√¢n b·ªë annotations theo class
        ax2 = plt.subplot(2, 2, 2)
        colors_pie = ['#FF6B6B', '#4ECDC4', '#45B7D1']
        labels_pie = [f"Class {cid}\n{category_mapping.get(cid, f'Class {cid}')}" 
                     for cid in class_ids]
        sizes_pie = ann_counts
        
        wedges, texts, autotexts = ax2.pie(sizes_pie, labels=labels_pie, autopct='%1.1f%%',
                                           colors=colors_pie[:len(sizes_pie)],
                                           startangle=90, textprops={'fontsize': 10})
        ax2.set_title('Ph√¢n b·ªë Annotations theo Class (%)', fontsize=14, fontweight='bold')
        
        # 3. Bi·ªÉu ƒë·ªì s·ªë l∆∞·ª£ng h√¨nh ·∫£nh c√≥/kh√¥ng c√≥ nh√£n
        ax3 = plt.subplot(2, 2, 3)
        labels_img = ['C√≥ nh√£n', 'Kh√¥ng c√≥ nh√£n']
        values_img = [total_images_with_labels, total_images_without_labels]
        colors_img = ['#4ECDC4', '#FF6B6B']
        
        bars2 = ax3.bar(labels_img, values_img, color=colors_img)
        ax3.set_ylabel('S·ªë l∆∞·ª£ng H√¨nh ·∫£nh', fontsize=12, fontweight='bold')
        ax3.set_title('S·ªë l∆∞·ª£ng H√¨nh ·∫£nh C√≥/Kh√¥ng c√≥ Nh√£n', fontsize=14, fontweight='bold')
        ax3.grid(axis='y', alpha=0.3)
        
        # Th√™m gi√° tr·ªã v√† ph·∫ßn trƒÉm
        total_images = total_images_with_labels + total_images_without_labels
        for bar, val in zip(bars2, values_img):
            height = bar.get_height()
            pct = (val / total_images * 100) if total_images > 0 else 0
            ax3.text(bar.get_x() + bar.get_width()/2., height,
                    f'{val:,}\n({pct:.1f}%)',
                    ha='center', va='bottom', fontsize=11, fontweight='bold')
        
        # 4. Bi·ªÉu ƒë·ªì s·ªë l∆∞·ª£ng annotations theo split
        ax4 = plt.subplot(2, 2, 4)
        splits = []
        ann_counts_by_split = []
        for split in SPLITS:
            if split in all_stats and all_stats[split] is not None:
                splits.append(split.upper())
                ann_counts_by_split.append(all_stats[split]['total_annotations'])
        
        bars3 = ax4.bar(splits, ann_counts_by_split, color=['#95E1D3', '#F38181', '#AA96DA'])
        ax4.set_xlabel('Split', fontsize=12, fontweight='bold')
        ax4.set_ylabel('S·ªë l∆∞·ª£ng Annotations', fontsize=12, fontweight='bold')
        ax4.set_title('S·ªë l∆∞·ª£ng Annotations theo Split', fontsize=14, fontweight='bold')
        ax4.grid(axis='y', alpha=0.3)
        
        # Th√™m gi√° tr·ªã l√™n m·ªói c·ªôt
        for bar, count in zip(bars3, ann_counts_by_split):
            height = bar.get_height()
            ax4.text(bar.get_x() + bar.get_width()/2., height,
                    f'{count:,}',
                    ha='center', va='bottom', fontsize=10, fontweight='bold')
        
        # ƒêi·ªÅu ch·ªânh layout
        plt.tight_layout()
        
        # L∆∞u bi·ªÉu ƒë·ªì
        chart_file = data_dir / "analysis_charts.png"
        plt.savefig(chart_file, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"‚úì ƒê√£ l∆∞u bi·ªÉu ƒë·ªì b√°o c√°o: {chart_file}")
        return chart_file
        
    except Exception as e:
        print(f"‚ö†Ô∏è  L·ªói khi t·∫°o bi·ªÉu ƒë·ªì: {e}")
        import traceback
        traceback.print_exc()
        return None

def print_summary(all_stats: Dict[str, Dict]):
    """In t√≥m t·∫Øt ra console"""
    print(f"\n{'=' * 70}")
    print("T√ìM T·∫ÆT PH√ÇN T√çCH")
    print(f"{'=' * 70}")
    
    total_images_json = sum(s['total_images_json'] for s in all_stats.values() if s)
    total_images_with_labels = sum(s['images_with_labels'] for s in all_stats.values() if s)
    total_images_without_labels = sum(s['images_without_labels'] for s in all_stats.values() if s)
    total_annotations = sum(s['total_annotations'] for s in all_stats.values() if s)
    
    total_category_annotations = defaultdict(int)
    for stats in all_stats.values():
        if stats:
            for cat_id, count in stats['category_annotations'].items():
                total_category_annotations[cat_id] += count
    
    # X√°c ƒë·ªãnh mapping t·ª± ƒë·ªông
    category_counts = count_category_occurrences(all_stats)
    category_mapping = determine_category_mapping(category_counts)
    
    print(f"\nüìä T·ªîNG QUAN:")
    print(f"  T·ªïng s·ªë h√¨nh ·∫£nh: {total_images_json:,}")
    print(f"  - C√≥ nh√£n: {total_images_with_labels:,}")
    print(f"  - Kh√¥ng c√≥ nh√£n: {total_images_without_labels:,}")
    print(f"  T·ªïng s·ªë annotations: {total_annotations:,}")
    
    print(f"\nüìä MAPPING T·ª∞ ƒê·ªòNG (d·ª±a tr√™n s·ªë l·∫ßn xu·∫•t hi·ªán):")
    sorted_counts = sorted(category_counts.items(), key=lambda x: x[1], reverse=True)
    for idx, (cat_id, count) in enumerate(sorted_counts, 1):
        cat_name = category_mapping.get(cat_id, f"category_{cat_id}")
        if idx == 1:
            rank_text = "NHI·ªÄU NH·∫§T ‚Üí R·∫ßy n√¢u (BPH)"
        elif idx == 2:
            rank_text = "TH·ª® 2 ‚Üí R·∫ßy l∆∞ng tr·∫Øng (WBPH)"
        elif idx == 3:
            rank_text = "√çT NH·∫§T ‚Üí S√¢u ƒÉn l√° l√∫a (RLM)"
        else:
            rank_text = f"X·∫æP H·∫†NG {idx}"
        print(f"  Class {cat_id} (YOLO) ({cat_name}): {count:,} l·∫ßn - {rank_text}")
    
    print(f"\nüìä THEO T·ª™NG LO·∫†I:")
    for category_id in sorted(total_category_annotations.keys()):
        cat_name = category_mapping.get(category_id, CATEGORY_NAMES.get(category_id, f"category_{category_id}"))
        ann_count = total_category_annotations.get(category_id, 0)
        if total_annotations > 0:
            pct = (ann_count / total_annotations) * 100
            print(f"  Class {category_id} (YOLO) - {cat_name}: {ann_count:,} annotations ({pct:.2f}%)")
    
    print(f"\n{'=' * 70}")

def main():
    """H√†m ch√≠nh"""
    print("=" * 70)
    print("PH√ÇN T√çCH D·ªÆ LI·ªÜU T·ª™ KS-NJ4/DATA")
    print("=" * 70)
    print(f"Th∆∞ m·ª•c d·ªØ li·ªáu: {DATA_DIR}")
    print(f"Splits: {', '.join(SPLITS)}")
    print("=" * 70)
    
    # Ki·ªÉm tra th∆∞ m·ª•c d·ªØ li·ªáu
    if not DATA_DIR.exists():
        print(f"‚ö†Ô∏è  Th∆∞ m·ª•c d·ªØ li·ªáu {DATA_DIR} kh√¥ng t·ªìn t·∫°i!")
        return
    
    # Ph√¢n t√≠ch t·ª´ng split
    all_stats = {}
    
    for split in SPLITS:
        stats = analyze_split(split, DATA_DIR)
        all_stats[split] = stats
    
    # In t√≥m t·∫Øt
    print_summary(all_stats)
    
    # T·∫°o b√°o c√°o chi ti·∫øt
    report_file = generate_report(all_stats, DATA_DIR)
    
    # T·∫°o bi·ªÉu ƒë·ªì b√°o c√°o
    if report_file:
        # T√≠nh to√°n l·∫°i c√°c gi√° tr·ªã c·∫ßn thi·∫øt cho bi·ªÉu ƒë·ªì
        total_images_json = sum(s['total_images_json'] for s in all_stats.values() if s)
        total_images_with_labels = sum(s['images_with_labels'] for s in all_stats.values() if s)
        total_images_without_labels = sum(s['images_without_labels'] for s in all_stats.values() if s)
        total_annotations = sum(s['total_annotations'] for s in all_stats.values() if s)
        
        total_category_annotations = defaultdict(int)
        for stats in all_stats.values():
            if stats:
                for cat_id, count in stats['category_annotations'].items():
                    total_category_annotations[cat_id] += count
        
        category_counts = count_category_occurrences(all_stats)
        category_mapping = determine_category_mapping(category_counts)
        
        create_charts(all_stats, category_mapping, total_images_with_labels, 
                     total_images_without_labels, total_annotations, 
                     dict(total_category_annotations), DATA_DIR)
    
    print(f"\n{'=' * 70}")
    print("HO√ÄN TH√ÄNH!")
    print(f"{'=' * 70}")
    print(f"B√°o c√°o ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {DATA_DIR / 'analysis_report.txt'}")
    print(f"Bi·ªÉu ƒë·ªì ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {DATA_DIR / 'analysis_charts.png'}")
    print(f"{'=' * 70}")

if __name__ == "__main__":
    main()

